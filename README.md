# suc-llama-cpp-python-colab-gpu
run llama cpp python on colab gpu freeeeee
